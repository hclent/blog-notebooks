{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Year in (Code) Review\n",
    "\n",
    "January is the time when people usually reflect on the past and create resolutions to improve themselves in the future. As such, I decided that this would also be a great time to **review some old code, identify weak spots, and build better coding habits for 2018**!\n",
    "\n",
    "To start, I began by looking at some code pushed to [my github](https://github.com/hclent) in 2017. It didn't take long to pick up on one pervasive pattern in my old code: an unwarented affinity for `for` loops, especially nested ones! For example, if you look through my old code, you may find something like this:\n",
    "\n",
    "```\n",
    "interesting_data = defaultdict(lambda:0) #initalized a dict of some data I'm interested in counting\n",
    "\n",
    "for item in some_list:\n",
    "    for i in item:\n",
    "        interesting_data[i] += 1 #add i to the dict as key, with count as value \n",
    "```\n",
    "\n",
    "Note the nested `for` loops!! If you don't immediately see why this code is problematic, keep reading! In this post, I will explore **alternatives to `for` loops**, including **benchmarking**, and I will show you how reducing the amount of `for` loops makes code:\n",
    "\n",
    "* More efficient\n",
    "* More readable\n",
    "* More functional (as in, functional programming)\n",
    "\n",
    "This post will be **useful for intermediate programmers looking for ways to take their programming to the next level**. All of the code snippits will also be available as a Jupyter notebook [here](https://github.com/hclent/blog-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's get to some code\n",
    "\n",
    "The code snippit I've chosen to review comes from my [Science Citation Knowledge Extractor](https://github.com/hclent/Science-Citation-Knowledge-Extractor) tool. More specifically, it comes from a script called [journalvis.py](https://github.com/hclent/Science-Citation-Knowledge-Extractor/blob/master/flask/journalvis.py), which is used to generate a data visualization like this:\n",
    "\n",
    "![journal vis](https://github.com/hclent/blog-notebooks/blob/master/images/journals.png)\n",
    "\n",
    "This is an interactive data visualization that shows the distribution of articles published in academic journals by year. The top row shows the total number of articles published each year, and the subsequent rows show the total number of articles published in that particular journal each year when the user hovers over it. \n",
    "\n",
    "Here is the code being used to generate the top row:\n",
    "```\n",
    "for year in range(2000, 2018+1):\n",
    "    yearDict[year]\n",
    "    for pair in journal_year:\n",
    "        if year == int(pair[1]):\n",
    "            yearDict[year] +=1\n",
    "```\n",
    "\n",
    "For each year, the code iterates through all of the pairs to see if there are any places where the range year and the publication year match up. If so it adds it to our dictionary. There's gotta be a better way to do this!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Its time to say goodbye to nested `for` loops!\n",
    "\n",
    "First, let's import our dependencies. I will use `random`, `string`, and `numpy` to generate example data, `time` to do benchmarking, and `unittest` to do unit testing. `Plotly` will be used to graph our benchmarking results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, string, time, unittest\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('#####', '######') #provide your username and API key to run Plotly in Jupyter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started benchmarking the code containg nested `for` loop, we are going to need to generate some fake data that is similar to the data processed by `journalvis.py`. **Below are 3 functions to generate some random data**: one that generates fake journal names, another that generates random years, and a third function that combines each journal name with a random year.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateJournalNames(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of fake journal names you want in the list.\n",
    "    Output: a List containing n number of strings, \n",
    "    each string is 3 random capital letters in ABCD\n",
    "    \"\"\"\n",
    "    list_of_journals = [(''.join(random.choice('ABCD') for _ in range(3))) for _ in range(n)]\n",
    "    return list_of_journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateYears(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of years (as Ints) that you want in the list. \n",
    "    (This will should match the the number of journals you generated).\n",
    "    Output: a List containing n number of years (Ints) between 2000 - 2018.\n",
    "    \"\"\"\n",
    "    years_list = list(np.random.choice(range(2000, 2018), n)) #np.random produces an array\n",
    "    return years_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of data points you want.\n",
    "    Output: zip object containg (journal, date) pairs, representative of \n",
    "    the real world data processed by the original code\n",
    "    \"\"\"\n",
    "    journals = generateJournalNames(n)\n",
    "    years_list = generateYears(n)\n",
    "    return zip(journals, years_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is a function that will be used to benchmark runtimes using the inefficient, nested `for` loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateDictInefficient(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of journals & dates\n",
    "    Output: Dict with year keys, and number values. \n",
    "    (E.g. {2000: 2, 2001: 1} means there were 2 articles published in journals in 2000,\n",
    "    and 1 article published in a journal in 2001)\n",
    "    ** This function is inefficient because of nested for loops! **\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yearDict = defaultdict(lambda:0) #initialize empty dict\n",
    "\n",
    "    #Generate random data\n",
    "    journal_year = list(generateData(n)) #e.g. ('Scientific Reports', 2006)\n",
    "\n",
    "    '''\n",
    "    For each year from 2000 to 2018, look at each (Journal, Year) pair.\n",
    "    If the year in the pair is the same as the year in range, +1 to the count in the dict.\n",
    "    '''\n",
    "    for year in range(2000, 2018+1):\n",
    "        yearDict[year] #make sure each year is represented in the default dict\n",
    "        for pair in journal_year:\n",
    "            if year == int(pair[1]):\n",
    "                yearDict[year] +=1\n",
    "    \n",
    "    #Keep track of time to see how inefficient this is\n",
    "    t1 = time.time() - t0\n",
    "    print(\"* finished in: \" + str(t1))\n",
    "    return yearDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.0003991127014160156\n",
      "example year dict: \n",
      "defaultdict(<function generateDictInefficient.<locals>.<lambda> at 0x116879268>, {2016: 0, 2017: 0, 2018: 0, 2000: 0, 2001: 0, 2002: 0, 2003: 0, 2004: 0, 2005: 2, 2006: 0, 2007: 0, 2008: 1, 2009: 1, 2010: 2, 2011: 1, 2012: 1, 2013: 1, 2014: 1, 2015: 0})\n",
      "* finished in: 0.0017399787902832031\n",
      "* finished in: 0.014203071594238281\n",
      "* finished in: 0.09611797332763672\n",
      "* finished in: 0.9227039813995361\n",
      "* finished in: 9.228466987609863\n",
      "* finished in: 87.46316599845886\n",
      "* done!\n"
     ]
    }
   ],
   "source": [
    "yd0 = generateDictInefficient(10)\n",
    "print(\"example year dict: \")\n",
    "print(yd0)\n",
    "generateDictInefficient(100)\n",
    "generateDictInefficient(1000)\n",
    "generateDictInefficient(10000)\n",
    "generateDictInefficient(100000)\n",
    "generateDictInefficient(1000000)\n",
    "generateDictInefficient(10000000)\n",
    "print(\"* done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `n=10` (journal, year) pairs, its easy to count in the first example that all 10 examples were added into the dictionary, and thus the code is behaving as expected and has no bugs! But can I be so sure about the rest? Before we move on to explore alternatives to the nested `for` loops, I'm going to **add a test function to make sure there are no mistakes in the code that could be artificially inflating our benchmarking!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCode0(unittest.TestCase):\n",
    "    \n",
    "    def test0(self):\n",
    "        '''The resulting dictionary should have the same size as the int argument used \n",
    "        to create it'''\n",
    "        result = generateDictInefficient(10000)\n",
    "        result_size = sum(result.values())\n",
    "        self.assertEqual(result_size, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.09419417381286621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.095s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#configuration to execute tests in Jupyter notebook\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our code passed the test! Now let's see if we can produce the same results with some more efficient code. \n",
    "\n",
    "### First, I will try a **dictionary comprehension**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateDictEfficient1(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of journals & dates\n",
    "    Output: Dict with year keys, and number values. {2018: 1}\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    #Generate random data\n",
    "    journal_year = generateData(n) #e.g. ('Scientific Reports', 2006)\n",
    "    \n",
    "    #pull out the years present in the data\n",
    "    data_years = [pair[1] for pair in journal_year]\n",
    "    \n",
    "    #create a list of the years we are interested in counting\n",
    "    all_years = [i for i in range(2000, 2019)]\n",
    "    \n",
    "    #dictionary comprehension\n",
    "    yearDict = {y: data_years.count(y) for y in all_years}    \n",
    "    \n",
    "    #Keep track of time to see how inefficient this is\n",
    "    t1 = time.time() - t0\n",
    "    print(\"* finished in: \" + str(t1))\n",
    "    return yearDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.00034999847412109375\n",
      "{2016: 0, 2017: 2, 2018: 0, 2000: 1, 2001: 0, 2002: 0, 2003: 2, 2004: 0, 2005: 2, 2006: 1, 2007: 0, 2008: 1, 2009: 0, 2010: 0, 2011: 0, 2012: 1, 2013: 0, 2014: 0, 2015: 0}\n",
      "* finished in: 0.0013248920440673828\n",
      "* finished in: 0.013056039810180664\n",
      "* finished in: 0.07970404624938965\n",
      "* finished in: 0.6227679252624512\n",
      "* finished in: 6.465986967086792\n",
      "* finished in: 62.540189027786255\n",
      "* done!\n"
     ]
    }
   ],
   "source": [
    "yd1 = generateDictEfficient1(10)\n",
    "print(yd1)\n",
    "generateDictEfficient1(100)\n",
    "generateDictEfficient1(1000)\n",
    "generateDictEfficient1(10000)\n",
    "generateDictEfficient1(100000)\n",
    "generateDictEfficient1(1000000)\n",
    "generateDictEfficient1(10000000)\n",
    "print(\"* done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we compare `generateInefficient` to `generateDictEfficient1`, let's make sure that the latter passes a test. After all, it doesn't matter if `generateDictEfficient1` is faster if it is producing incorrect results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCode1(unittest.TestCase):\n",
    "    \n",
    "    def test1(self):\n",
    "        '''The resulting dictionary should have the same size as the int argument used \n",
    "        to create it'''\n",
    "        result = generateDictEfficient1(10000)\n",
    "        result_size = sum(result.values())\n",
    "        self.assertEqual(result_size, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.1074988842010498\n",
      "* finished in: 0.07501983642578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.184s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#configuration to execute tests in Jupyter notebook\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since `generateEfficient1` passes the test, now let's compare it to the nested `for` loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create traces\n",
    "x_axis = [10, 100, 1000, 10000, 100000, 1000000, 10000000] \n",
    "\n",
    "inefficient = go.Scatter(\n",
    "    x = x_axis,\n",
    "    y = [0.00039, 0.00173, 0.014203, 0.096117, 0.9227, 9.22846, 87.4631],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'inefficient'\n",
    ")\n",
    "\n",
    "efficient1 = go.Scatter(\n",
    "    x = x_axis,\n",
    "    y = [0.00034, 0.00132, 0.01305, 0.0797, 0.6227, 6.465, 62.5401], \n",
    "    mode = 'lines+markers',\n",
    "    name = 'efficient1'\n",
    ")\n",
    "\n",
    "data=go.Data([inefficient, efficient1])\n",
    "\n",
    "layout = dict(title = 'Benchmarking',\n",
    "              xaxis = dict(title = 'N data points'),\n",
    "              yaxis = dict(title = 'Time in seconds'),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hclent/66.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig0 = dict(data=data, layout=layout)\n",
    "py.iplot(fig0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the nested `for` loops (blue) scale worse than the dictionary comprehension (orange). But in the case of our journal visualization, its unlikely that there will ever be a situation to visualize more than a few thousand journals. With `Plotly`, you can zoom in closer and see that there aren't any large gains for lower N values. I'm going to keep refining this code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, I will try creating a smaller, helper function to help make the code more efficient \n",
    "\n",
    "Similarly to the dictionary comprehension, it is preferable to only iterate through our pairs of `(Journal, Year)`s only once. Here, I will make a smaller function called `getUpdateValue`, which will allow me to figure out the current value for a giving year in the dictionary, add +1 for the year I'm looking at, then return size 1 dictionary, which I will use to `dict.update()` our yearDict in `generateDictEfficient2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getUpdateValue(x, yearDict):\n",
    "    \"\"\"\n",
    "    Input: x is a zip object (journal[String], year[Int]);\n",
    "           yearDict is the most recent version of the dictionary. \n",
    "    Output: a dict containing the updated value for a particular year, e.g. {2000: 1}.\n",
    "    This output dict will be used to UPDATE the yearDict of generateDictEfficient2().\n",
    "    \"\"\"\n",
    "    year = x[1] #year is the second element of the zip obj\n",
    "    value = yearDict[year] #retrieve the previous val of the yearDict for the year\n",
    "    update_dict = {year: value+1} #add 1 to it\n",
    "    return update_dict #return the current value for the year as a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateDictEfficient2(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of journals & dates\n",
    "    Output: Dict with year keys, and number values. \n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    \n",
    "    yearDict = {y: 0 for y in range(2000, 2018+1)} #dictionary comprehension to init dict\n",
    "    \n",
    "    #Generate random data\n",
    "    journal_year = generateData(n) #e.g. ('Scientific Reports', 2006)\n",
    "    \n",
    "    '''\n",
    "    First attempt to create our dict without a nested for loop.\n",
    "    Although, we still have the for loop above to initliaze the dictionary...\n",
    "    \n",
    "    Here, I use a list comprehension that loops through each (journal, year) pair once. \n",
    "    \n",
    "    This is better than the generateDictInefficient() method, which loops through\n",
    "    all (journal, year) zip objects 18 times each! \n",
    "    \n",
    "    For each zip object, the \"getUpdateValue\" function is called which:\n",
    "    1) makes a copy of the current dictionary\n",
    "    2) adds the next year count to an update_dict\n",
    "    3) updates the values of yearDict with newly added values in update_dict\n",
    "    '''\n",
    "    update_dict = [yearDict.update( getUpdateValue(x, yearDict)  ) for x in journal_year]\n",
    "    \n",
    "    #Keep track of time to see how inefficient this is\n",
    "    t1 = time.time() - t0\n",
    "    print(\"* finished in: \" + str(t1))\n",
    "    return yearDict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.00020194053649902344\n",
      "{2016: 1, 2017: 2, 2018: 0, 2000: 0, 2001: 0, 2002: 0, 2003: 0, 2004: 0, 2005: 0, 2006: 1, 2007: 1, 2008: 0, 2009: 0, 2010: 1, 2011: 1, 2012: 1, 2013: 1, 2014: 0, 2015: 1}\n",
      "* finished in: 0.0006451606750488281\n",
      "* finished in: 0.005680084228515625\n",
      "* finished in: 0.06321096420288086\n",
      "* finished in: 0.5303189754486084\n",
      "* finished in: 5.539263010025024\n",
      "* finished in: 53.45106482505798\n",
      "* done!\n"
     ]
    }
   ],
   "source": [
    "yd2 = generateDictEfficient1(10)\n",
    "print(yd2)\n",
    "generateDictEfficient2(100)\n",
    "generateDictEfficient2(1000)\n",
    "generateDictEfficient2(10000)\n",
    "generateDictEfficient2(100000)\n",
    "generateDictEfficient2(1000000)\n",
    "generateDictEfficient2(10000000)\n",
    "print(\"* done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we compare `generateDictEfficient2` to the other methods, let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCode2(unittest.TestCase):\n",
    "    \n",
    "    def test2(self):\n",
    "        '''The resulting dictionary should have the same size as the int argument used \n",
    "        to create it'''\n",
    "        result = generateDictEfficient2(10000)\n",
    "        result_size = sum(result.values())\n",
    "        self.assertEqual(result_size, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.10398197174072266\n",
      "* finished in: 0.07726287841796875\n",
      "* finished in: 0.0549161434173584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.239s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#configuration to execute tests in Jupyter notebook\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It passes the test! So now let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a trace for generateEfficient2\n",
    "efficient2 = go.Scatter(\n",
    "    x = x_axis,\n",
    "    y = [0.0002, 0.0006, 0.0056, 0.0632, 0.5303, 5.5392, 53.4510], \n",
    "    mode = 'lines+markers',\n",
    "    name = 'efficient2'\n",
    ")\n",
    "\n",
    "data2 = go.Data([inefficient, efficient1, efficient2])\n",
    "\n",
    "layout2 = dict(title = 'Benchmarking',\n",
    "              xaxis = dict(title = 'N data points'),\n",
    "              yaxis = dict(title = 'Time in seconds'),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hclent/68.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1 = dict(data=data2, layout=layout2)\n",
    "py.iplot(fig1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing the small helper function `getUpdateValue`, I managed to **reduce runtime by ~20 seconds** when `n=10million`! However between the dictionary comprehension (`efficient1`, orange) and the small helper function (`efficient2`, green), the later doesn't save us too much time. \n",
    "\n",
    "Now that we've seen dictionary comprehension and helper function solutions to this problem, I wanted to compare how much faster is a single `for` loop than the nested `for` loop? Are `efficient1` and `efficient2` much more scalable than just using a single `for` loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateDictEfficientFor(n):\n",
    "    \"\"\"\n",
    "    Input: n (Int) number of journals & dates\n",
    "    Output: Dict with year keys, and number values. \n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #Generate random data\n",
    "    journal_year = generateData(n)\n",
    "        \n",
    "    yearDict = {y: 0 for y in range(2000, 2018+1)} #dictionary comprehension to init dict\n",
    "       \n",
    "    for jy in journal_year:\n",
    "        yearDict[jy[1]] += 1 \n",
    "    \n",
    "    #Keep track of time to see how inefficient this is\n",
    "    t1 = time.time() - t0\n",
    "    print(\"* finished in: \" + str(t1))\n",
    "    return yearDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.00024008750915527344\n",
      "{2016: 1, 2017: 1, 2018: 0, 2000: 0, 2001: 1, 2002: 1, 2003: 0, 2004: 0, 2005: 0, 2006: 0, 2007: 2, 2008: 1, 2009: 1, 2010: 1, 2011: 0, 2012: 1, 2013: 0, 2014: 0, 2015: 0}\n",
      "* finished in: 0.0006899833679199219\n",
      "* finished in: 0.008743047714233398\n",
      "* finished in: 0.059123992919921875\n",
      "* finished in: 0.47548699378967285\n",
      "* finished in: 4.88400411605835\n",
      "* finished in: 48.08178186416626\n",
      "* done!\n"
     ]
    }
   ],
   "source": [
    "yd3 = generateDictEfficientFor(10)\n",
    "print(yd3)\n",
    "generateDictEfficientFor(100)\n",
    "generateDictEfficientFor(1000)\n",
    "generateDictEfficientFor(10000)\n",
    "generateDictEfficientFor(100000)\n",
    "generateDictEfficientFor(1000000)\n",
    "generateDictEfficientFor(10000000)\n",
    "print(\"* done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCodeFor(unittest.TestCase):\n",
    "    \n",
    "    def test3(self):\n",
    "        '''The resulting dictionary should have the same size as the int argument used to create it'''\n",
    "        result = generateDictEfficientFor(100)\n",
    "        result_size = sum(result.values())\n",
    "        self.assertEqual(result_size, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* finished in: 0.09809994697570801\n",
      "* finished in: 0.07302403450012207\n",
      "* finished in: 0.05312514305114746\n",
      "* finished in: 0.0006167888641357422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.228s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#configuration to execute tests in Jupyter notebook\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a trace for generateDictEfficientFor\n",
    "oneForLoop = go.Scatter(\n",
    "    x = x_axis,\n",
    "    y = [0.0002, 0.0006, 0.0087, 0.0591, 0.47548, 4.8840, 48.0817],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'generateDictEfficientFor'\n",
    ")\n",
    "\n",
    "data3 =go.Data([inefficient, efficient1, efficient2, oneForLoop])\n",
    "\n",
    "layout3 = dict(title = 'Benchmarking',\n",
    "              xaxis = dict(title = 'N data points'),\n",
    "              yaxis = dict(title = 'Time in seconds'),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hclent/70.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3 = dict(data=data3, layout=layout3)\n",
    "py.iplot(fig3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single `for` loop wins here for speed. Although the dictionary comprehension and helper function only need to iterate through each data point once, the functions take longer because there is more pre-processing. For example, in `generateEfficient1` these pre-processing steps slow it down:\n",
    "\n",
    "```\n",
    "data_years = [pair[1] for pair in journal_year]\n",
    "    \n",
    "all_years = [i for i in range(2000, 2019)]\n",
    "```\n",
    "Here, the `for` loop has the benefit of being able to use the `+= 1` syntax, that is not available for dictionary comprehensions or list comprehensions. Having to only add to the values in a dictionary, rather than count items and then update a dictionary, is faster. \n",
    "\n",
    "But what about the readablility of the `for` loop? It still adds more lines to the code and therefore is less appealing. Again, since for such a data visualization as `journalvis.py`, there will probably not be a use case where 10million articles need to be accounted for. Up to 10k journals, the benchmarking time for `generateEfficient2` is very close to `generateEfficientFor`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In conclusion \n",
    "\n",
    "Reviewing old code I wrote helped me to learn:\n",
    "\n",
    "* To be more mindful of my code. Even if a piece of my code produces what I want, I should review that code again to see if I can make it more efficient and/or readable.\n",
    "* Nesting `for` loops should be avoided and there are several other efficient, clean, and/or functional programming-based alternatives! \n",
    "    * Although its not the fastest, I thought `efficient1`'s use of the dictionary comprehension was the most readable.\n",
    "\n",
    "Besides these main learning points, this code review also made me think about:\n",
    "\n",
    "* Writing tests in Python. I frequently write tests in Scala, but have had little exposure to writing tests in Python. I would like to learn more about this!\n",
    "* Adding docstrings to my code! Although I typically comment my code well, it is more likely that someone using my code will try to access the docstring for a method, than read the source code. \n",
    "\n",
    "Did you learn anything from this post? Do you have any ideas for alternative ways to approach this problem? Do I miss anything in this post? **If you would like to run any of this code, it is available on github [here](https://github.com/hclent/blog-notebooks/blob/master/code_review1.ipynb) as a Jupyter notebook.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
